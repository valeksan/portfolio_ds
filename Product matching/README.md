# Исследовательская работа: Мэтчинг товаров

[HTML](https://github.com/valeksan/portfolio_ds/blob/main/Product%20matching/P1_Portfolio.html)     [ipynb](https://github.com/valeksan/portfolio_ds/blob/main/Product%20matching/P1_Portfolio.ipynb)

## Описание проекта

Нам доступны некие закодированные данные, мы не знаем какие характеристики товаров они выражают, можем только провести их анализ.
Итак, нам доступно следующее:
* `base.csv`. Датасет со всеми доступными товарами. Анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
* `train.csv`. Обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из base.csv, который максимально похож на него (по мнению экспертов).
* `validation.csv`. Валидационный датасет. Датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из `base.csv`.
* `validation_answer.csv`. Правильные ответы к валидационной выборки.

Датасет base содержат индексы товаров, обезличенные признаки товаров.
Будем считать “правильные ответы” индексами наиболее подходящих товаров-аналогов (кроме валидационного датасета - для него “правильные ответы” содержатся в отдельном файле). Есть возможность выбрать, работать с более объемными датасетами (более 2 Гб), либо выбрать уменьшенный вариант (~10% от исходной версия датасета), ниже это можно выбрать поправив соответствующую константу.

**Задача:** <br>
разработать алгоритм, который для всех товаров из `validation.csv` предложит несколько вариантов наиболее похожих товаров из base. Оценить качество алгоритма по метрике `accuracy@5`, попытаться добиться наилучшей метрики подбирая разные рабочие параметры.

## Навыки и инструменты

- **python**
- **pandas**
- **numpy**
- **matplotlib**
- **seaborn**
- **phik**
- sklearn.preprocessing.**RobustScaler**
- **faiss**

##

## Общий вывод

**Результаты:**

Разработан алгоритм мэтчинга с метрикой Accuracy@5 ~= 75%.
Поиск документов проходит относительно быстро.

**Accuracy@5 (на тренировочной выборке): 75.9%**

**Accuracy@5 (на валидационной выборке): 75.4%**

Параметры:
* *nprobe = 5*
* *n_cells = 500*

---

**Замечния:**

Во всех датафреймах обнаружили полные дубликаты:
* **df_base** - *11278 дубликатов*
* **df_train** - *243 дубликатов*
* **df_valid** - *265 дубликатов*
* **valid_answer** - *265 дубликатов (по индексам!).*

Были обнаружены признаки с ненормальными распределениями.

Были обнаружены выбросы почти во всех признаках (по диаграмме размаха).
