# Предсказание музыкального жанра

[ipynb](https://github.com/valeksan/portfolio_ds/blob/main/Music%20genre%20prediction/P2_Portfolio.ipynb) | [html](https://github.com/valeksan/portfolio_ds/blob/main/Music%20genre%20prediction/P2_Portfolio.html) | [просмотр](https://valeksan.github.io/P2_Portfolio.html)

## Описание проекта

Стриминговый сервис "МиФаСоль".  \
Сервис расширяет работу с новыми артистами и музыкантами, в связи с чем возникла задача правильно классифицировать новые музыкальные треки, чтобы улучшить работу рекомендательной системы.  \
Был подготовлен датасет, в котором собраны некоторые характеристики музыкальных произведений и их жанры.

**Задача: разработать модель, позволяющую классифицировать музыкальные произведения по жанрам.**

### Описание полей данных

* `instance_id` - Уникальный идентификатор трека
* `track_name` - Название трека
* `acousticness` - Мера уверенности от 0,0 до 1,0 в том, что трек является акустическим. 1,0 означает высокую степень уверенности в том, что трек является акустическим.
* `danceability` - Танцевальность описывает, насколько трек подходит для танцев, основываясь на сочетании музыкальных элементов, включая темп, стабильность ритма, силу ударов и общую регулярность. Значение 0,0 означает наименьшую танцевальность, а 1,0 - наибольшую танцевальность.
* `duration_ms` - Продолжительность трека в миллисекундах.
`energy` - Энергия это показатель от 0,0 до 1,0, представляющий собой меру интенсивности и активности. Как правило, энергичные композиции ощущаются как быстрые, громкие и шумные. Например, дэт-метал обладает высокой энергией, в то время как прелюдия Баха имеет низкую оценку этого параметра
* `instrumentalness` - Определяет, содержит ли трек вокал. Звуки "Ooh" и "aah" в данном контексте рассматриваются как инструментальные. Рэп или разговорные треки явно являются "вокальными". Чем ближе значение инструментальности к 1,0, тем больше вероятность того, что трек не содержит вокала
* `key` - базовый ключ (нота) произведения
* `liveness` - Определяет присутствие аудитории в записи. Более высокие значения liveness означают увеличение вероятности того, что трек был исполнен вживую. Значение выше 0,8 обеспечивает высокую вероятность того, что трек исполняется вживую
* `loudness` - Общая громкость трека в децибелах (дБ)
* `mode` - Указывает на модальность (мажорную или минорную) трека
* `speechiness` - Речевой характер определяет наличие в треке разговорной речи. Чем более исключительно речевой характер носит запись (например, ток-шоу, аудиокнига, поэзия), тем ближе значение атрибута к 1,0. Значения выше 0,66 характеризуют треки, которые, вероятно, полностью состоят из разговорной речи. Значения от 0,33 до 0,66 характеризуют треки, которые могут содержать как музыку, так и речь, как в виде фрагментов, так и в виде слоев, включая такие случаи, как рэп-музыка. Значения ниже 0,33, скорее всего, представляют музыку и другие неречевые треки.
* `tempo` - Темп трека в ударах в минуту (BPM). В музыкальной терминологии темп представляет собой скорость или темп данного произведения и напрямую зависит от средней продолжительности тактов
* `obtained_date` - дата загрузки в сервис
* `valence` - Показатель от 0,0 до 1,0, характеризующий музыкальный позитив, передаваемый треком. Композиции с высокой валентностью звучат более позитивно (например, радостно, весело, эйфорично), а композиции с низкой валентностью - более негативно (например, грустно, депрессивно, сердито)
* `music_genre` - Музыкальный жанр трека (целевой признак).

### Основные этапы работ

* загрузка и ознакомление с данными,
* предварительная обработка,
* полноценный разведочный анализ,
* разработка новых синтетических признаков,
* проверка на мультиколлинеарность,
* отбор финального набора обучающих признаков,
* выбор и обучение моделей,
* итоговая оценка качества предсказания лучшей модели,
* анализ важности ее признаков.

## Навыки и инструменты

- **python**
- **pandas**
- **numpy**
- **re**
- **matplotlib**
- **seaborn**
- **phik**
- ydata_profiling.**ProfileReport**
- imblearn.pipeline.**Pipeline**
- imblearn.base.**FunctionSampler**
- feature_engine.selection.**DropCorrelatedFeatures**
- sklearn.preprocessing.**OrdinalEncoder**
- sklearn.preprocessing.**StandardScaler**
- sklearn.impute.**SimpleImputer**
- sklearn.impute.**IterativeImputer**
- sklearn.compose.**ColumnTransformer**
- sklearn.compose.**make_column_selector**
- sklearn.compose.**make_column_transformer**
- sklearn.ensemble.**IsolationForest**
- sklearn.ensemble.**RandomForestClassifier**
- sklearn.model_selection.**train_test_split**
- sklearn.model_selection.**cross_val_score**
- sklearn.model_selection.**RandomizedSearchCV**
- sklearn.metrics.**f1_score**
- sklearn.metrics.**classification_report**
- catboost.**CatBoostClassifier**
- **shap**

##

## Общий вывод

**Основное:**
* В ходе работ была разработана модель, позволяющую классифицировать музыкальные произведения по жанрам, в качестве лучшего классификатора было решено взять CatBoostClassifier, он дал лучшую метрику при подборе гиперпараметров.
* Были опробованы новые ранее незнакомые инструменты для работы с данными (например такие как `shap`, `IterativeImputer`, `DropCorrelatedFeatures`, ... ).
* Была освоена методология работы с конвеером (pipeline).
* В ходе работ был создан файл с ответами модели по тестовым данным, который был использован в соревновании на платформе [Kaggle](https://www.kaggle.com/competitions/music-genre-prediction-m126ds/leaderboard) 12 место с f1=0.47137. 

**Замечания:**
* В поле `duration_ms` в более 10% данных были выбросы константным значением в -1.0, боло решено считать это за пропуск, но на всякий случай лучше уточнить этот момент.
* В полях `key`,`mode` и `tempo` что в тренировочных, что в тестовых данных - наблюдаются пропуски, необходимо понять из-за чего они возникают (если бы это была полноценная работа).
